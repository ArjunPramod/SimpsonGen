{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm import tqdm\n",
        "import imageio as iio\n",
        "from torchvision.utils import make_grid\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "from torchsummary import summary\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torchvision.utils as vutils\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from IPython.display import display, Image"
      ],
      "metadata": {
        "id": "4qa6GnM3f0Vv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the display_image_grid function\n",
        "def display_image_grid(images, rows, cols, title):\n",
        "    fig, axs = plt.subplots(rows, cols, figsize=(10, 10))\n",
        "    axs = axs.ravel()\n",
        "\n",
        "    for i in range(rows * cols):\n",
        "        img = transforms.ToPILImage()(images[i])\n",
        "        axs[i].imshow(img)\n",
        "        axs[i].axis('off')\n",
        "\n",
        "    plt.suptitle(title)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "HzR0kJDVphlW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing and Dataset"
      ],
      "metadata": {
        "id": "Q9SKT456dvBp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the device to GPU if available, otherwise use CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Download and extract the dataset\n",
        "!wget https://www.dropbox.com/s/g0w7a3x1aw3oonf/SimpsonFaces.zip?dl=0\n",
        "!unzip -o SimpsonFaces.zip?dl=0 -d extracted_data -x '__MACOSX/*'\n",
        "\n",
        "# Custom Dataset Class\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, image_path, transform):\n",
        "        self.image_path = image_path\n",
        "        self.images = os.listdir(image_path)\n",
        "        self.transform = transform\n",
        "        self._check_images()\n",
        "\n",
        "    def _check_images(self):\n",
        "        valid_images = []\n",
        "        for img_name in self.images:\n",
        "            img_path = os.path.join(self.image_path, img_name)\n",
        "            try:\n",
        "                iio.v2.imread(img_path)\n",
        "                valid_images.append(img_name)\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading image {img_path}: {e}. Skipping...\")\n",
        "                os.remove(img_path)\n",
        "\n",
        "        self.images = valid_images\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        im_path = os.path.join(self.image_path, self.images[idx])\n",
        "        im = iio.v2.imread(im_path)\n",
        "        im = self.transform(im)\n",
        "        return im\n",
        "\n",
        "# Data Transformation\n",
        "trans = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize([128, 128]),\n",
        "    transforms.RandomRotation(5),\n",
        "    transforms.RandomHorizontalFlip(0.1),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Create DataLoader\n",
        "batch_size = 32\n",
        "dataset = MyDataset(\"extracted_data/cropped/\", trans)\n",
        "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "kJ4NhYQnerh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generator and Discriminator Architecture"
      ],
      "metadata": {
        "id": "7Voll69kfpMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generator Model\n",
        "class Reshape(nn.Module):\n",
        "    def __init__(self, shape):\n",
        "        super(Reshape, self).__init__()\n",
        "        self.shape = shape\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x.view(*self.shape)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, Z):\n",
        "        super(Generator, self).__init__()\n",
        "        self.Z = Z\n",
        "\n",
        "        self.gen_model = nn.Sequential(\n",
        "            nn.Linear(self.Z, 1024*8*8),\n",
        "            nn.BatchNorm1d(1024*8*8),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            Reshape((-1, 1024, 8, 8)),\n",
        "            nn.ConvTranspose2d(1024, 512, 5, 2, 1, 0),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.ConvTranspose2d(512, 256, 5, 2, 2, 0),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.ConvTranspose2d(256, 128, 5, 2, 2, 0),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.ConvTranspose2d(128, 64, 5, 2, 2, 1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(64, 3, 5, 1, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, noise):\n",
        "        x = self.gen_model(noise)\n",
        "        x = torch.tanh(x)\n",
        "        return x\n",
        "\n",
        "# Discriminator Model\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.disc_model = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=5, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=5, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=5, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=5, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=5, stride=2, padding=2),\n",
        "            nn.BatchNorm2d(1024),\n",
        "            nn.LeakyReLU(0.2),\n",
        "        )\n",
        "        self.linearization = nn.Sequential(\n",
        "            nn.Flatten(1, -1),\n",
        "            nn.Linear(1024*8*8, 1)\n",
        "        )\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.disc_model(x)\n",
        "        x = self.linearization(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "# Weight Initialization\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)\n",
        "\n",
        "# Generator and Discriminator Instances\n",
        "Z = 100\n",
        "generator = Generator(Z).to(device)\n",
        "discriminator = Discriminator().to(device)\n",
        "generator.apply(weights_init)\n",
        "discriminator.apply(weights_init)\n",
        "\n",
        "# Hyperparameters and Training\n",
        "EPOCHS = 50\n",
        "lrg = 0.0002\n",
        "lrd = 0.0002\n",
        "\n",
        "# Training Function\n",
        "def train_GAN(EPOCHS, lrg, lrd, discriminator, generator, save_path='models/'):\n",
        "    real_label = 1\n",
        "    fake_label = 0\n",
        "\n",
        "    discriminator.train()\n",
        "    generator.train()\n",
        "\n",
        "    optimizer_gen = torch.optim.Adam(generator.parameters(), lr=lrg, betas=(0.5, 0.999))\n",
        "    optimizer_disc = torch.optim.Adam(discriminator.parameters(), lr=lrd, betas=(0.5, 0.999))\n",
        "    loss_fn = nn.BCELoss()\n",
        "\n",
        "    generator_losses = []\n",
        "    discriminator_losses = []\n",
        "    generated_images = []\n",
        "\n",
        "    for epoch in range(1, EPOCHS + 1):\n",
        "        pbar = tqdm(train_loader)\n",
        "\n",
        "        total_gen_loss = 0.0\n",
        "        total_disc_loss = 0.0\n",
        "        num_samples = 0\n",
        "\n",
        "        sample_noise = torch.randn(10, Z).to(device)\n",
        "\n",
        "        for batch in pbar:\n",
        "            inputs = batch\n",
        "            inputs = inputs.to(device)\n",
        "            inputs = (inputs - 0.5) * 2\n",
        "\n",
        "            optimizer_disc.zero_grad()\n",
        "            label = torch.full((inputs.shape[0], 1), real_label, dtype=torch.float, device=device)\n",
        "            output_real = discriminator(inputs)\n",
        "            errD_real = loss_fn(output_real, label)\n",
        "            errD_real.backward()\n",
        "\n",
        "            D_x = output_real.mean().item()\n",
        "\n",
        "            noise = torch.randn(inputs.shape[0], Z).to(device)\n",
        "            fake = generator(noise)\n",
        "            label.fill_(fake_label)\n",
        "            output_fake = discriminator(fake.detach())\n",
        "            errD_fake = loss_fn(output_fake, label)\n",
        "            errD_fake.backward()\n",
        "\n",
        "            D_G_z1 = output_fake.mean().item()\n",
        "            errD = errD_real + errD_fake\n",
        "            optimizer_disc.step()\n",
        "\n",
        "            optimizer_gen.zero_grad()\n",
        "            label.fill_(real_label)\n",
        "            output_fake = discriminator(fake)\n",
        "            errG = loss_fn(output_fake, label)\n",
        "            errG.backward()\n",
        "            D_G_z2 = output_fake.mean().item()\n",
        "            optimizer_gen.step()\n",
        "\n",
        "            total_gen_loss += errG.item()\n",
        "            total_disc_loss += errD.item()\n",
        "            num_samples += inputs.size(0)\n",
        "\n",
        "            pbar.set_description(f\"Epoch {epoch}/{EPOCHS}: \")\n",
        "            pbar.set_postfix({\n",
        "                \"generator_loss\": errG.item(),\n",
        "                \"discriminator_loss\": errD.item(),\n",
        "                \"D(x)\": D_x,\n",
        "                \"D(G(z1))\": D_G_z1,\n",
        "                \"D(G(z2))\": D_G_z2\n",
        "            })\n",
        "\n",
        "        generator_losses.append(total_gen_loss / num_samples)\n",
        "        discriminator_losses.append(total_disc_loss / num_samples)\n",
        "\n",
        "        generations = generator(sample_noise).cpu()\n",
        "        generations = (generations + 1) / 2\n",
        "        generations = (generations * 255).clamp(0, 255).to(torch.uint8)\n",
        "        generated_images.append(generations)\n",
        "\n",
        "        display_image_grid(generations, 1, 10, f\"Generated images at epoch {epoch}\")\n",
        "\n",
        "        torch.save(generator.state_dict(), os.path.join(save_path, f'generator_epoch_{epoch}.pth'))\n",
        "        torch.save(discriminator.state_dict(), os.path.join(save_path, f'discriminator_epoch_{epoch}.pth'))\n",
        "\n",
        "    return generator_losses, discriminator_losses, generated_images\n",
        "\n",
        "\n",
        "# Specify the path where you want to save the models\n",
        "save_path = 'models/'\n",
        "\n",
        "# Ensure the directory exists before saving models\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "# Train GAN with model saving\n",
        "generator_losses, discriminator_losses, generated_images = train_GAN(EPOCHS, lrg, lrd, discriminator, generator, save_path)"
      ],
      "metadata": {
        "id": "JOYOpcqkgDQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Display Generated Images"
      ],
      "metadata": {
        "id": "Gbc7HzIcj6nL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display generated images collage\n",
        "test_images = (generator(torch.randn(200, Z).to(device)).cpu() + 1) / 2\n",
        "test_images = (test_images * 255).clamp(0, 255).to(torch.uint8)\n",
        "\n",
        "plt.figure(figsize=(30, 60))\n",
        "for i in range(200):\n",
        "    plt.subplot(20, 10, i + 1)\n",
        "    plt.imshow(np.clip(test_images[i].permute(1, 2, 0), 0, 255), interpolation='nearest', aspect='auto')\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "plt.subplots_adjust(wspace=0, hspace=0)\n",
        "plt.savefig('collage_images.png', bbox_inches='tight', pad_inches=0)\n",
        "with open('collage_images.png', 'rb') as f:\n",
        "    display(Image(data=f.read(), format='png'))"
      ],
      "metadata": {
        "id": "P1LV8eb3kWAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize Training Progress"
      ],
      "metadata": {
        "id": "c9EAgtXlkpYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot loss curve\n",
        "def plot_loss(generator_losses, discriminator_losses):\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(generator_losses, label='Generator Loss')\n",
        "    plt.plot(discriminator_losses, label='Discriminator Loss')\n",
        "    plt.title('Generator and Discriminator Losses')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "plot_loss(generator_losses, discriminator_losses)"
      ],
      "metadata": {
        "id": "gtByLwM_kjdw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save generated images as GIF\n",
        "frames = []\n",
        "for epoch_images in generated_images:\n",
        "    epoch_grid = np.zeros((128, 128 * 10, 3), dtype=np.uint8)\n",
        "    for i, image in enumerate(epoch_images):\n",
        "        image = image.permute(1, 2, 0)\n",
        "        h_start, h_end = i * 128, (i + 1) * 128\n",
        "        epoch_grid[:, h_start:h_end, :] = image\n",
        "    frames.append(epoch_grid)\n",
        "\n",
        "iio.mimsave('generated_images.gif', frames, duration=0.1)\n",
        "with open('generated_images.gif', 'rb') as f:\n",
        "    display(Image(data=f.read(), format='gif'))"
      ],
      "metadata": {
        "id": "P4dCaIEzk-Oo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create and Display GIFs"
      ],
      "metadata": {
        "id": "tICLKEk6lEgK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to create a GIF from a list of images\n",
        "# def create_gif(images, filename, duration=0.1):\n",
        "#     frames = []\n",
        "#     for image in images:\n",
        "#         # Convert the image from (3, 128, 128) to (128, 128, 3) as imageio requires the channel dimension at the end\n",
        "#         image = image.permute(1, 2, 0).numpy()\n",
        "#         frames.append((image * 255).astype(np.uint8))\n",
        "\n",
        "#     iio.mimsave(filename, frames, duration=duration)\n",
        "\n",
        "# Extract the 5th image from each epoch and create a GIF for them\n",
        "images_at_index_4 = [epoch[4] for epoch in generated_images]\n",
        "create_gif(images_at_index_4, 'generated_image_index_4.gif')\n",
        "\n",
        "# Extract the 3rd image from each epoch and create a GIF for them\n",
        "images_at_index_3 = [epoch[3] for epoch in generated_images]\n",
        "create_gif(images_at_index_3, 'generated_image_index_3.gif')\n",
        "\n",
        "# Display the GIFs\n",
        "with open('generated_image_index_4.gif', 'rb') as f:\n",
        "    display(Image(data=f.read(), format='gif'))\n",
        "with open('generated_image_index_3.gif', 'rb') as f:\n",
        "    display(Image(data=f.read(), format='gif'))"
      ],
      "metadata": {
        "id": "cbLj_nP9k_Tp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to Create GIF\n",
        "def create_gif(images, filename, duration=0.1):\n",
        "    frames = []\n",
        "    for image in images:\n",
        "        image = image.permute(1, 2, 0).numpy()\n",
        "        frames.append((image * 255).astype(np.uint8))\n",
        "\n",
        "    iio.mimsave(filename, frames, duration=duration)\n",
        "\n",
        "# Display the GIFs\n",
        "def display_gif(filename):\n",
        "    with open(filename, 'rb') as f:\n",
        "        display(Image(data=f.read(), format='png'))\n",
        "\n",
        "display_gif('generated_images.gif')"
      ],
      "metadata": {
        "id": "56QnQPvqlSYC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}